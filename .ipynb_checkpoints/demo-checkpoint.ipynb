{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import networkx as nx\n",
    "import re\n",
    "import community as community_louvain\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from netwulf import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roam_json_path = Path(\"~/Dropbox/roam-bak/roamnotes/json/roamwsy.json\").expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_markdown_path = Path(\"~/Dropbox/roam-bak/roamnotes/markdown/\").expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_markdown_path = Path(\"~/Dropbox/obsidian\").expanduser()/\"subset_markdowns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_term = \"Roam Research\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_in_custom_filter(mystr, stopwords):\n",
    "    for stopword in stopwords:\n",
    "        if re.fullmatch(stopword, mystr):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_page(page, graph, custom_filter=False, stopwords=None):\n",
    "    regex = r\"'string': '.*?\\[\\[(.+?)\\]\\].*?',\"\n",
    "    test_str = str(page)\n",
    "    matches = re.findall(regex, test_str, re.MULTILINE)\n",
    "    source = page['title']\n",
    "    if not custom_filter: # no filter\n",
    "        for target in matches:\n",
    "            graph.add_edge(source, target)\n",
    "    else: # use custom filter\n",
    "        if str_in_custom_filter(source, stopwords): # source is todo, done or daily page\n",
    "            pass\n",
    "        else: # source is common page\n",
    "            for target in matches:\n",
    "                if not str_in_custom_filter(target, stopwords): # target is not todo, done or daily page\n",
    "                    graph.add_edge(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(roam_json_path) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in data:\n",
    "    analyze_page(page, nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_nx_graph = nx_graph.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = community_louvain.best_partition(bi_nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clutser_query = partition[query_term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in bi_nx_graph:\n",
    "    if partition[node] == clutser_query:\n",
    "        cluster_nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cluster_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not target_markdown_path.exists():\n",
    "    target_markdown_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in cluster_nodes:\n",
    "    mdfilename = f\"{node}.md\"\n",
    "    try:\n",
    "        shutil.copy2(source_markdown_path/mdfilename, target_markdown_path/mdfilename)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_nx_graph = nx_graph.subgraph(cluster_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(sub_nx_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
